import os
import pandas as pd
from tqdm import tqdm
import json
import numpy as np
from sklearn.metrics import roc_curve, auc
from sklearn.metrics.pairwise import cosine_similarity
import matplotlib.pyplot as plt
import random
from sentence_transformers import SentenceTransformer

# í—ˆê¹…í˜ì´ìŠ¤ ëª¨ë¸ ì´ë¦„ ì„¤ì • (ì—¬ëŸ¬ ì˜µì…˜ ì¤‘ ì„ íƒ)
model_name = 'jhgan/ko-sroberta-multitask'  # ë‹¤êµ­ì–´ ëª¨ë¸






print(f'Loading embedding model: {model_name}')

# í—ˆê¹…í˜ì´ìŠ¤ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
embeddings_model = SentenceTransformer(model_name)
print(f'Embedding model loaded: {embeddings_model}')

# CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv("hanja.csv")  # íŒŒì¼ ê²½ë¡œë¥¼ ì—¬ê¸°ì— ì…ë ¥

# 'hanja'ì™€ 'radical' ì»¬ëŸ¼ë§Œ ì¶”ì¶œ
hanjas = df['hanja'].dropna().unique()
radicals = df['radical'].dropna().unique()

# ì¤‘ë³µ ì œê±°ëœ í•œì ë° ë¶€ìˆ˜ ë¦¬ìŠ¤íŠ¸
unique_items = list(set(hanjas.tolist() + radicals.tolist()))

# ì„ë² ë”© ê²°ê³¼ ì €ì¥ ë”•ì…”ë„ˆë¦¬
embeddings = {}

# âœ… ë°°ì¹˜ ê¸°ë°˜ ì„ë² ë”© í•¨ìˆ˜
def embed_texts_batch(text_list, embeddings={}, batch_size=64):
    # ì¤‘ë³µ ìš”ì²­ ë°©ì§€: ì´ë¯¸ ìˆëŠ” ê±´ ê±´ë„ˆëœ€
    new_texts = [text for text in text_list if text not in embeddings]
    
    for i in tqdm(range(0, len(new_texts), batch_size), desc="ì„ë² ë”© ì¤‘"):
        batch = new_texts[i:i+batch_size]
        try:
            # í—ˆê¹…í˜ì´ìŠ¤ ëª¨ë¸ì„ í†µí•œ ë°°ì¹˜ ì„ë² ë”© ìƒì„±
            batch_embeddings = embeddings_model.encode(batch, convert_to_numpy=True)
            
            # ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ì— ì €ì¥
            for text, embedding in zip(batch, batch_embeddings):
                embeddings[text] = embedding.tolist()  # JSON ì €ì¥ì„ ìœ„í•´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                
        except Exception as e:
            print(f"ë°°ì¹˜ {i // batch_size + 1} ì„ë² ë”© ì‹¤íŒ¨: {e}")
   
    return embeddings

# ğŸ§  ì„ë² ë”© ìˆ˜í–‰
embeddings = embed_texts_batch(unique_items, embeddings)

# ê²°ê³¼ ì €ì¥
model_name_safe = model_name.replace('/', '_')
with open(f"{model_name_safe}_embeddings.json", "w", encoding="utf-8") as f:
    json.dump(embeddings, f, ensure_ascii=False, indent=2)

print("âœ… ì„ë² ë”© ì™„ë£Œ ë° json ì €ì¥ë¨.")

def calculate_roc_for_hanja_radical_pairs(df, embeddings):
    # ê¸ì •ì  ìŒ(ì‹¤ì œ í•œì-ë¶€ìˆ˜ ê´€ê³„) ë° ë¶€ì •ì  ìŒ(ë¬´ì‘ìœ„ ìŒ) ìƒì„±
    similarities = []
    y_true = []
    positive_pairs = []
    
    # ì‹¤ì œ í•œì-ë¶€ìˆ˜ ìŒ ì¶”ì¶œ (ê¸ì •ì  ì¼€ì´ìŠ¤)
    valid_rows = df.dropna(subset=['hanja', 'radical'])
    
    for _, row in valid_rows.iterrows():
        hanja = row['hanja']
        radical = row['radical']
        
        # ì„ë² ë”©ì´ ìˆëŠ”ì§€ í™•ì¸
        if hanja in embeddings and radical in embeddings:
            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° - sklearn í•¨ìˆ˜ ì‚¬ìš©
            hanja_vector = np.array(embeddings[hanja]).reshape(1, -1)
            radical_vector = np.array(embeddings[radical]).reshape(1, -1)
            
            similarity = cosine_similarity(hanja_vector, radical_vector)[0][0]
            
            similarities.append(similarity)
            y_true.append(1)  # ì‹¤ì œ ìŒì€ 1ë¡œ ë ˆì´ë¸”
            positive_pairs.append((hanja, radical))
    
    # ë¬´ì‘ìœ„ í•œì-ë¶€ìˆ˜ ìŒ ìƒì„± (ë¶€ì •ì  ì¼€ì´ìŠ¤)
    hanjas_with_embeddings = [h for h in hanjas if h in embeddings]
    radicals_with_embeddings = [r for r in radicals if r in embeddings]
    
    random.seed(42)
    
    negative_count = 0
    max_attempts = len(positive_pairs) * 5
    attempts = 0
    
    while negative_count < len(positive_pairs) and attempts < max_attempts:
        random_hanja = random.choice(hanjas_with_embeddings)
        random_radical = random.choice(radicals_with_embeddings)
        
        # ì´ë¯¸ ì‹¤ì œ ìŒì¸ ê²½ìš° ê±´ë„ˆë›°ê¸°
        if (random_hanja, random_radical) not in positive_pairs:
            hanja_vector = np.array(embeddings[random_hanja]).reshape(1, -1)
            radical_vector = np.array(embeddings[random_radical]).reshape(1, -1)
            
            similarity = cosine_similarity(hanja_vector, radical_vector)[0][0]
            
            similarities.append(similarity)
            y_true.append(0)  # ë¬´ì‘ìœ„ ìŒì€ 0ìœ¼ë¡œ ë ˆì´ë¸”
            negative_count += 1
        
        attempts += 1
    
    # ROC ì»¤ë¸Œ ë° AUC ê³„ì‚°
    y_scores = np.array(similarities)
    y_true = np.array(y_true)
    
    fpr, tpr, thresholds = roc_curve(y_true, y_scores)
    roc_auc = auc(fpr, tpr)
    
    return fpr, tpr, roc_auc, thresholds

# ROC ì»¤ë¸Œ ê³„ì‚°
fpr, tpr, roc_auc, thresholds = calculate_roc_for_hanja_radical_pairs(df, embeddings)

# ROC ì»¤ë¸Œ ì‹œê°í™”
plt.figure(figsize=(10, 8))
plt.plot(fpr, tpr, color='darkorange', lw=2, 
         label=f'ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title(f'Embedding similarity of Hanja-radical relation ROC curve\nModel: {model_name}')
plt.legend(loc="lower right")
plt.grid(True)
plt.savefig(f"{model_name_safe}_roc_curve.png")
plt.show()

# ìµœì  ì„ê³„ê°’ ì°¾ê¸°
# AUC ê°’ ì¶œë ¥
print(f"ROC ì»¤ë¸Œì˜ AUC ì ìˆ˜: {roc_auc:.4f}")
optimal_idx = np.argmax(tpr - fpr)
optimal_threshold = thresholds[optimal_idx]
print(f"ìµœì  ì„ê³„ê°’: {optimal_threshold:.4f}")
print(f"ì´ ì„ê³„ê°’ì—ì„œì˜ TPR: {tpr[optimal_idx]:.4f}, FPR: {fpr[optimal_idx]:.4f}")



# ê²°ê³¼ ë°ì´í„° ë°±ì—…
with open(f"ROC-AUC_{model_name_safe}.txt", "w", encoding="utf-8") as f:
    f.write(f"Model: {model_name}\n")
    f.write(f"AUC: {roc_auc}\n")
    f.write(f"Optimal threshold: {optimal_threshold}\n")
    f.write(f"TPR at optimal threshold: {tpr[optimal_idx]}\n")
    f.write(f"FPR at optimal threshold: {fpr[optimal_idx]}")